{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is based on Slawek Biel's notebook (https://www.kaggle.com/slawekbiel/positive-score-with-detectron-2-3-training)\n\nI added copy-paste data augmentation method from https://www.kaggle.com/slavkoprytula/detectron2-copy-paste-augmentation","metadata":{}},{"cell_type":"markdown","source":"## Transfer learning\nThese notebooks ([train](https://www.kaggle.com/markunys/sartorius-transfer-learning-train), [inference](https://www.kaggle.com/markunys/sartorius-transfer-learning-inference)) show how to do transfer learning with LIVECell dataset.","metadata":{}},{"cell_type":"code","source":"#Taken from https://www.kaggle.com/markunys/sartorius-transfer-learning-train-with-livecell\n!pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-28T14:58:36.634276Z","iopub.execute_input":"2021-12-28T14:58:36.635506Z","iopub.status.idle":"2021-12-28T15:02:31.84576Z","shell.execute_reply.started":"2021-12-28T14:58:36.635351Z","shell.execute_reply":"2021-12-28T15:02:31.844321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import detectron2\nfrom pathlib import Path\nimport random, cv2, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pycocotools.mask as mask_util\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.structures import polygons_to_bitmask\nfrom detectron2.evaluation import inference_on_dataset, print_csv_format\nfrom detectron2.utils import comm\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:31.850582Z","iopub.execute_input":"2021-12-28T15:02:31.850975Z","iopub.status.idle":"2021-12-28T15:02:33.415748Z","shell.execute_reply.started":"2021-12-28T15:02:31.850928Z","shell.execute_reply":"2021-12-28T15:02:33.414737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Copy-Paste implementation taken from https://www.kaggle.com/slavkoprytula/detectron2-copy-paste-augmentation\nimport pandas as pd\nimport numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook as tqdm\nfrom datetime import datetime\nimport time\nimport matplotlib.pyplot as plt\nfrom pycocotools.coco import COCO\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nfrom pathlib import Path\nfrom typing import Optional\n\n\nfrom tqdm import tqdm\nimport itertools\n\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom glob import glob\nimport numba\nfrom numba import jit\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom detectron2.structures import BoxMode\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import Visualizer\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\n\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:33.417447Z","iopub.execute_input":"2021-12-28T15:02:33.418894Z","iopub.status.idle":"2021-12-28T15:02:36.161146Z","shell.execute_reply.started":"2021-12-28T15:02:33.418846Z","shell.execute_reply":"2021-12-28T15:02:36.160176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone \"https://github.com/MarkPotanin/copy_paste_aug_detectron2\"\n!cp -r ./copy_paste_aug_detectron2/* ./","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:36.164913Z","iopub.execute_input":"2021-12-28T15:02:36.165188Z","iopub.status.idle":"2021-12-28T15:02:39.574269Z","shell.execute_reply.started":"2021-12-28T15:02:36.165145Z","shell.execute_reply":"2021-12-28T15:02:39.573025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom copy_paste import CopyPaste\nfrom coco import CocoDetectionCP\nfrom visualize import display_instances\nimport albumentations as A\nimport random\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:39.578556Z","iopub.execute_input":"2021-12-28T15:02:39.578953Z","iopub.status.idle":"2021-12-28T15:02:39.595317Z","shell.execute_reply.started":"2021-12-28T15:02:39.578918Z","shell.execute_reply":"2021-12-28T15:02:39.594206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the LIVECell data","metadata":{}},{"cell_type":"code","source":"dataDir=Path('../input/sartorius-cell-instance-segmentation/')\ncfg = get_cfg()\n\nDatasetCatalog.clear()\nMetadataCatalog.clear()\n\nregister_coco_instances('sartorius_train',{}, '../input/5foldcleaned/coco_cell_train_fold5_polygon.json', dataDir)\nregister_coco_instances('sartorius_val',{}, '../input/5foldcleaned/coco_cell_valid_fold5_polygon.json', dataDir) \n\n\nmetadata = MetadataCatalog.get('sartorius_train')\ndataset_train = DatasetCatalog.get('sartorius_train')\ndataset_valid = DatasetCatalog.get('sartorius_val')","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:39.596965Z","iopub.execute_input":"2021-12-28T15:02:39.597306Z","iopub.status.idle":"2021-12-28T15:02:44.59939Z","shell.execute_reply.started":"2021-12-28T15:02:39.597263Z","shell.execute_reply":"2021-12-28T15:02:44.598359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18,11))\nd=dataset_valid[5] \nimg = cv2.imread(d[\"file_name\"])\n\nv = Visualizer(img[:, :, ::-1],\n                metadata=metadata, \n                scale=1,\n                instance_mode=ColorMode.IMAGE_BW\n    )\nout = v.draw_dataset_dict(d)\nax.grid(False)\nax.axis('off')\nax.imshow(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:44.601074Z","iopub.execute_input":"2021-12-28T15:02:44.601498Z","iopub.status.idle":"2021-12-28T15:02:45.493228Z","shell.execute_reply.started":"2021-12-28T15:02:44.601452Z","shell.execute_reply":"2021-12-28T15:02:45.491798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nfrom torchvision.datasets import CocoDetection\nfrom copy_paste import copy_paste_class\nimport torch.utils.data as data\nfrom PIL import Image\nimport os\nimport os.path\n\nmin_keypoints_per_image = 10\n\ndef _count_visible_keypoints(anno):\n    return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n\ndef _has_only_empty_bbox(anno):\n    return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n\ndef has_valid_annotation(anno):\n    if len(anno) == 0:\n        return False\n    if _has_only_empty_bbox(anno):\n        return False\n    if \"keypoints\" not in anno[0]:\n        return True\n    if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n        return True\n\n    return False\n\n@copy_paste_class\nclass CocoDetectionCP(CocoDetection):\n    def __init__(\n        self,\n        root,\n        annFile,\n        transforms\n    ):\n        super(CocoDetectionCP, self).__init__(\n            root, annFile, None, None, transforms\n        )\n\n        ids = []\n        for img_id in self.ids:\n            ann_ids = self.coco.getAnnIds(imgIds=[img_id], iscrowd=None)\n            anno = self.coco.loadAnns(ann_ids)\n            if has_valid_annotation(anno):\n                ids.append(img_id)\n        self.ids = ids\n\n    def load_example(self, index):\n        img_id = self.ids[index]\n        ann_ids = self.coco.getAnnIds(imgIds=[img_id])\n        target = self.coco.loadAnns(ann_ids)\n\n        path = self.coco.loadImgs([img_id])[0]['file_name']\n        image = cv2.imread(os.path.join(self.root, path))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        masks = []\n        bboxes = []\n        for ix, obj in enumerate(target):\n            masks.append(self.coco.annToMask(obj))\n            bboxes.append(obj['bbox'] + [obj['category_id']] + [ix])\n\n        output = {\n            'image': image,\n            'masks': masks,\n            'bboxes': bboxes\n        }\n        \n        return self.transforms(**output)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:45.494463Z","iopub.execute_input":"2021-12-28T15:02:45.494814Z","iopub.status.idle":"2021-12-28T15:02:45.518276Z","shell.execute_reply.started":"2021-12-28T15:02:45.494758Z","shell.execute_reply":"2021-12-28T15:02:45.517061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([A.HorizontalFlip(p=0.5),A.Flip(p=0.5),\n        CopyPaste(blend=True, sigma=1, pct_objects_paste=0.5, p=1.0)\n    ], bbox_params=A.BboxParams(format=\"coco\", min_visibility=0.95)\n)\n\ndata = CocoDetectionCP(\n    \"../input/sartorius-cell-instance-segmentation\", \n    '../input/5foldcleaned/coco_cell_train_fold5_polygon.json', \n    transform\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:45.519839Z","iopub.execute_input":"2021-12-28T15:02:45.520303Z","iopub.status.idle":"2021-12-28T15:02:47.241711Z","shell.execute_reply.started":"2021-12-28T15:02:45.520256Z","shell.execute_reply":"2021-12-28T15:02:47.240682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    img_data = data[1]\n\n    f, ax = plt.subplots(1, 2, figsize=(16, 16))\n    image = img_data['image']\n    masks = img_data['masks']\n    bboxes = img_data['bboxes']\n\n    empty = np.array([])\n    display_instances(image, empty, empty, empty, empty, show_mask=False, show_bbox=False, ax=ax[0])\n\n    if len(bboxes) > 0:\n        boxes = np.stack([b[:4] for b in bboxes], axis=0)\n        box_classes = np.array([b[-2] for b in bboxes])\n        mask_indices = np.array([b[-1] for b in bboxes])\n        show_masks = np.stack(masks, axis=-1)[..., mask_indices]\n        class_names = {k: data.coco.cats[k]['name'] for k in data.coco.cats.keys()}\n        display_instances(image, boxes, show_masks, box_classes, class_names, show_bbox=True, ax=ax[1])\n    else:\n        display_instances(image, empty, empty, empty, empty, show_mask=False, show_bbox=False, ax=ax[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:02:47.243457Z","iopub.execute_input":"2021-12-28T15:02:47.243811Z","iopub.status.idle":"2021-12-28T15:03:28.42938Z","shell.execute_reply.started":"2021-12-28T15:02:47.243766Z","shell.execute_reply":"2021-12-28T15:03:28.424942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA = {i:q for q,i in enumerate(data.ids)}\nIDS = list(DATA.keys())\ndataset_dicts_train = [i for i in dataset_train if i['image_id'] in IDS]","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:03:28.4314Z","iopub.execute_input":"2021-12-28T15:03:28.432026Z","iopub.status.idle":"2021-12-28T15:03:28.444637Z","shell.execute_reply.started":"2021-12-28T15:03:28.431981Z","shell.execute_reply":"2021-12-28T15:03:28.443592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycocotools import mask\nfrom skimage import measure\n\nclass MyMapper:\n    def __init__(self, cfg, is_train: bool = True):\n        self.is_train = is_train\n\n    def __call__(self, dataset_dict):\n        dataset_dict = copy.deepcopy(dataset_dict) \n        img_id = dataset_dict['image_id']\n        \n        aug_sample = data[DATA[img_id]]\n        image = aug_sample['image']\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n        \n        bboxes = aug_sample['bboxes']\n        box_classes = np.array([b[-2] for b in bboxes])\n        boxes = np.stack([b[:4] for b in bboxes], axis=0)\n        mask_indices = np.array([b[-1] for b in bboxes])\n        masks = aug_sample['masks']\n        annos = []\n        \n        for enum, index in enumerate(mask_indices):\n            curr_mask = masks[index]\n            _gt_binary_mask = np.asfortranarray(curr_mask)\n            encoded_ground_truth = mask.encode(_gt_binary_mask)\n            _area = mask.area(encoded_ground_truth)\n            _gt_bounding_box = mask.toBbox(encoded_ground_truth)\n            contours = measure.find_contours(curr_mask, 0.5)\n            \n            annotation = {\n                \"segmentation\": [],\n                \"iscrowd\": 0,\n                \"bbox\": _gt_bounding_box.tolist(), \n                \"category_id\": metadata.thing_dataset_id_to_contiguous_id[box_classes[enum]],\n                \"bbox_mode\": dataset_train[0]['annotations'][0]['bbox_mode'],\n            }\n            \n            for contour in contours:\n                contour = np.flip(contour, axis=1)\n                segmentation = contour.ravel().tolist()\n                annotation[\"segmentation\"].append(segmentation)\n            annos.append(annotation)\n        \n        image_shape = image.shape[:2]\n        \n        instances = utils.annotations_to_instances(annos, image_shape)\n        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n        \n        return dataset_dict","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:03:28.447449Z","iopub.execute_input":"2021-12-28T15:03:28.448145Z","iopub.status.idle":"2021-12-28T15:03:28.465814Z","shell.execute_reply.started":"2021-12-28T15:03:28.448099Z","shell.execute_reply":"2021-12-28T15:03:28.464779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nimport pycocotools.mask as mask_util\nfrom detectron2.data import DatasetMapper\nfrom detectron2.modeling import build_model, GeneralizedRCNNWithTTA\n\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ))\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp / (tp + fp + fn)\n        prec.append(p)\n        \n    return np.mean(prec)\n\n\nclass MAPIOUEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n            \n    def reset(self):\n        self.scores = []\n\n    def process(self, inputs, outputs):\n        for inp, out in zip(inputs, outputs):\n            if len(out['instances']) == 0:\n                self.scores.append(0)    \n            else:\n                targ = self.annotations_cache[inp['image_id']]\n                self.scores.append(score(out, targ))\n\n    def evaluate(self):\n        return {\"MaP IoU\": np.mean(self.scores)}","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:03:28.469456Z","iopub.execute_input":"2021-12-28T15:03:28.469879Z","iopub.status.idle":"2021-12-28T15:03:28.487585Z","shell.execute_reply.started":"2021-12-28T15:03:28.469847Z","shell.execute_reply":"2021-12-28T15:03:28.486535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polygon_to_rle(polygon, shape=(520, 704)):\n    #print(polygon)\n    mask = polygons_to_bitmask([np.asarray(polygon) + 0.25], shape[0], shape[1])\n\n    rle = mask_util.encode(np.asfortranarray(mask))\n    return rle\n\n# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ))\n    enc_targs = [polygon_to_rle(enc_targ[0]) for enc_targ in enc_targs]\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp / (tp + fp + fn)\n        prec.append(p)\n    return np.mean(prec)\n\nclass MAPIOUEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n            \n    def reset(self):\n        self.scores = []\n\n    def process(self, inputs, outputs):\n        for inp, out in zip(inputs, outputs):\n            if len(out['instances']) == 0:\n                self.scores.append(0)    \n            else:\n                targ = self.annotations_cache[inp['image_id']]\n                self.scores.append(score(out, targ))\n\n    def evaluate(self):\n        return {\"MaP IoU\": np.mean(self.scores)}\n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:03:28.492785Z","iopub.execute_input":"2021-12-28T15:03:28.493026Z","iopub.status.idle":"2021-12-28T15:03:28.513632Z","shell.execute_reply.started":"2021-12-28T15:03:28.492991Z","shell.execute_reply":"2021-12-28T15:03:28.512549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=MyMapper(cfg),)\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        return MAPIOUEvaluator(dataset_name)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T15:03:28.515507Z","iopub.execute_input":"2021-12-28T15:03:28.515912Z","iopub.status.idle":"2021-12-28T15:03:28.527986Z","shell.execute_reply.started":"2021-12-28T15:03:28.515852Z","shell.execute_reply":"2021-12-28T15:03:28.52683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define evaluator \nGenerates lines like this in the training output:\n`[10/27 18:31:26 d2.evaluation.testing]: copypaste: MaP IoU=0.2192638391201311` \n\nSee here for definition: https://www.kaggle.com/c/sartorius-cell-instance-segmentation/overview/evaluation\n\nI've made some modifications, because LIVECell coco data is not bitmask but polygon.","metadata":{}},{"cell_type":"markdown","source":"### Train\n\nTraining for 100 iterations here for demonstration.\n\nI trained the model for about 100000 iterations and selected best model.","metadata":{}},{"cell_type":"code","source":"dataDir=Path('../input/sartorius-cell-instance-segmentation/')\ncfg = get_cfg()\n\nDatasetCatalog.clear()\nMetadataCatalog.clear()\n\nregister_coco_instances('sartorius_train',{}, '../input/5foldcleaned/coco_cell_train_fold5_polygon.json', dataDir)\nregister_coco_instances('sartorius_val',{}, '../input/5foldcleaned/coco_cell_valid_fold5_polygon.json', dataDir) \n\nmetadata = MetadataCatalog.get('sartorius_train')\ntrain_ds = DatasetCatalog.get('sartorius_train')\nvalid_ds = DatasetCatalog.get('sartorius_val')\n\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"sartorius_train\")\ncfg.DATASETS.TEST = (\"sartorius_val\",)\ncfg.DATALOADER.NUM_WORKERS = 8\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 1\ncfg.SOLVER.BASE_LR = 0.0005 \ncfg.SOLVER.MAX_ITER = 10000\ncfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\ncfg.INPUT.MASK_FORMAT='polygon'\ncfg.SOLVER.STEPS = []       \ncfg.SOLVER.CHECKPOINT_PERIOD = (len(DatasetCatalog.get('sartorius_train')) ) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64   \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\ncfg.TEST.EVAL_PERIOD = (len(DatasetCatalog.get('sartorius_train')) ) // cfg.SOLVER.IMS_PER_BATCH   # Once per epoch\n\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\nprint(cfg.OUTPUT_DIR)\ntrainer = MyTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-28T15:03:28.529851Z","iopub.execute_input":"2021-12-28T15:03:28.530217Z","iopub.status.idle":"2021-12-28T20:05:33.489011Z","shell.execute_reply.started":"2021-12-28T15:03:28.530146Z","shell.execute_reply":"2021-12-28T20:05:33.48782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ./output/model_final.pth","metadata":{"execution":{"iopub.status.busy":"2021-12-28T20:05:33.491397Z","iopub.execute_input":"2021-12-28T20:05:33.493031Z","iopub.status.idle":"2021-12-28T20:05:34.395768Z","shell.execute_reply.started":"2021-12-28T20:05:33.492948Z","shell.execute_reply":"2021-12-28T20:05:34.394668Z"},"trusted":true},"execution_count":null,"outputs":[]}]}